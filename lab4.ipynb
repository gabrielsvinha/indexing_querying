{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 - RECINFO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Execute o algoritmo ilustrado na Fig. 5.8 do livro texto (pag. 157) para gerar um índice similar o mostrado na Fig. 5.4 (pag. 134). Guarde o índice em disco em formato csv. (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/vinha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to /home/vinha/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/vinha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/vinha/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "import heapq\n",
    "\n",
    "import pandas\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('rslp')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "url = \"https://raw.githubusercontent.com/gabrielsvinha/text_processing/master/input.csv\"\n",
    "news_list = pandas.read_csv(url).replace(np.nan, '', regex=True)\n",
    "documents_cc = news_list.text.count()\n",
    "words = []\n",
    "\n",
    "tokenizer = RegexpTokenizer('''\\w+[-']*\\w*''')\n",
    "sw = stopwords.words(\"portuguese\")\n",
    "\n",
    "for entry in news_list.text:\n",
    "    tokens = []\n",
    "    for token in tokenizer.tokenize(entry):\n",
    "        if token not in sw and len(token) > 3:\n",
    "             tokens.append(token)\n",
    "    words.extend(tokens)\n",
    "\n",
    "\n",
    "    \n",
    "def build(data):\n",
    "    index_v = 0\n",
    "    index = {\"row\": []}\n",
    "    for entry in data.text:\n",
    "        index_v += 1\n",
    "        index[\"row\"].append(index_v)\n",
    "        for word in words:\n",
    "            if word in index:\n",
    "                if index_v in index[word]:\n",
    "                    index[word][index_v] = index[word][index_v] + 1\n",
    "                else:\n",
    "                    index[word][index_v] = 1\n",
    "            else:\n",
    "                index[word] = {index_v: 1}\n",
    "    return index\n",
    "\n",
    "i = build(news_list)\n",
    "\n",
    "with open(\"index_built.csv\", \"w+\") as myfile:\n",
    "    writer = csv.DictWriter(myfile, i.keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerow(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Implemente as abordagens de processamento de consulta documento-por-vez e termo-por-vez (Fig. 5.16 e 5.18). (2 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defina 5 consultas de um termo somente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = [\"juíza\", \"federal\", \"lula\", \"punida\", \"Hospital\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term: juíza  - Rank: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Term: federal  - Rank: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Term: lula  - Rank: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Term: punida  - Rank: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Term: Hospital  - Rank: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "def document_at_time(query, i, k):\n",
    "    r = {}\n",
    "    a = []\n",
    "    if query in i:\n",
    "        a.append(i[query])\n",
    "    for doc in i[\"row\"]:\n",
    "        r[doc] = 0\n",
    "        for inv_list in a:\n",
    "            for inv_list_id, inv_list_w in inv_list.items():\n",
    "                if inv_list_id == doc:\n",
    "                    r[doc] = r[doc] + inv_list_w\n",
    "    return heapq.nlargest(k, r, r.get)\n",
    "    \n",
    "\n",
    "for query in q:\n",
    "    print(\"Term:\",query, \" - Rank:\", document_at_time(query, i, 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dê evidências de que sua implementação está correta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare os tempos médios de execução e uso de memória de cada algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Implemente uma das versões de consulta conjuntiva (AND) (Fig. 5.20 ou 5.21). (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defina 5 consultas conjuntivas (AND)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute as 5 consultas em cada algoritmo retornando os top-10 documentos (parâmetro k do algoritmo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dê evidências de que sua implementação está correta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
